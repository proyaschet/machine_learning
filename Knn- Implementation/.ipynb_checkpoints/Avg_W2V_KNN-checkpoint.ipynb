{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/reiinakano/scikit-plot.git && pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('/mydata/final.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_sql_query(\"\"\" SELECT * FROM Reviews\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = final[final.Score == 'positive']\n",
    "positive = positive.sample(frac=0.035,random_state=1)\n",
    "\n",
    "negative = final[final.Score == 'negative']\n",
    "negative = negative.sample(frac=0.15,random_state=1)\n",
    "\n",
    "final = pd.concat([positive,negative],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "final[\"Time\"] = final[\"Time\"].map(lambda t: datetime.datetime.fromtimestamp(int(t)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "final = final.sort_values('Time',axis=0,kind=\"quicksort\", ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = final['Score']\n",
    "final = final.drop(\"Score\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final, l, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Word2Vec model using Text Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordList(sentence):\n",
    "    listword = []\n",
    "    for sent in sentence:\n",
    "        listword.append(sent.split())\n",
    "    return listword\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_clean_text = wordList(X_train['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_clean_text_test = wordList(X_test['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'poetri', 'month', 'year', 'goe', 'month', 'cute', 'littl', 'poem', 'along', 'love', 'book', 'realli', 'fun', 'way', 'learn', 'month', 'poem', 'creativ', 'author', 'purpos', 'write', 'book', 'give', 'children', 'fun', 'way', 'learn', 'month', 'children', 'also', 'learn', 'thing', 'poetri', 'rhythm', 'read', 'book']\n"
     ]
    }
   ],
   "source": [
    "print(list_clean_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering Words with minimum occurence of 5 times\n",
    "w2v_model = Word2Vec(list_clean_text, min_count = 5, size = 50, workers = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words occuring more than 5 times 4943\n",
      "sample words ['much', 'easier', 'use', 'past', 'color', 'vibrant', 'frost', 'like', 'simpl', 'make', 'mess', 'complaint', 'find', 'year', 'ago', 'must', 'decor', 'often', 'book', 'month', 'goe', 'cute', 'littl', 'along', 'love', 'realli', 'fun', 'way', 'learn', 'creativ', 'author', 'purpos', 'write', 'give', 'children', 'also', 'thing', 'read', 'product', 'remind', 'thousand', 'lunch', 'chicken', 'teriyaki', 'mound', 'steam', 'rice', 'eat', 'drizzl', 'soy']\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words occuring more than 5 times\", len(w2v_words))\n",
    "print(\"sample words\", w2v_words[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2vavg(clean):\n",
    "    sent_vectors = [] # the avg-w2v for each sentence/review is stored in this list\n",
    "    for sent in clean:\n",
    "        sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "        cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "        for word in sent: # for each word in a review/sentence\n",
    "            if word in w2v_words:\n",
    "                vec = w2v_model.wv[word]\n",
    "                sent_vec += vec\n",
    "                cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "            sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "    return sent_vectors\n",
    "\n",
    "        \n",
    "#print(len(sent_vectors))\n",
    "#print(len(sent_vectors[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors_train = w2vavg(list_clean_text)\n",
    "print(len(sent_vectors_train))\n",
    "print(len(sent_vectors_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "sent_vectors_test = w2vavg(list_clean_text_test)\n",
    "print(len(sent_vectors_test))\n",
    "print(len(sent_vectors_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors_final_train = np.asarray(sent_vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors_final_test = np.asarray(sent_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sent_vectors_final_train.shape)\n",
    "print(sent_vectors_final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data = s.fit_transform(sent_vectors_final_train)\n",
    "standardized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data_test = s.transform(sent_vectors_final_test)\n",
    "standardized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 17.\n"
     ]
    }
   ],
   "source": [
    "def kneigh(x,y,algo):\n",
    "    myList = list(range(0,50))\n",
    "    neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "    cv_scores = []\n",
    "    for k in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k,algorithm=algo, n_jobs = -1) # Creating K-NN classifier with KD3 Algorithm\n",
    "        scores = cross_val_score(knn, x, y, cv=10, scoring='accuracy')\n",
    "        cv_scores.append(scores.mean())\n",
    "     \n",
    "    MSE = [1 - x for x in cv_scores]\n",
    "    optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "    plt.plot(neighbors, MSE,color='blue', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\n",
    "    plt.xlabel('Number of Neighbors K')\n",
    "    plt.ylabel('Misclassification Error')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"the misclassification error for each k value is : \", np.round(MSE,3))\n",
    "    return optimal_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 49 is 84.277778%\n"
     ]
    }
   ],
   "source": [
    "def kneighpredict(k,x,y,z,algo):\n",
    "    knn_optimal = KNeighborsClassifier(n_neighbors=k, algorithm=algo, n_jobs = -1)\n",
    "    knn_optimal.fit(X_train, y_train)\n",
    "    pred = knn_optimal.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred) * 100\n",
    "    skplt.plot_confusion_matrix(y_test ,pred)\n",
    "    print(classification_report(y_test ,pred))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = kneigh(standardized_data,y_train,'kd_tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = kneighpredict(optimal_k,standardized_data,y_train,standardized_data_test ,'kd_tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = kneigh(standardized_data,y_train,'brute')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = kneighpredict(optimal_k,standardized_data,y_train,standardized_data_test ,'kd_tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
