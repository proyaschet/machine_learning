{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/reiinakano/scikit-plot.git && pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "import scikitplot.metrics as skplt\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('/mydata/final.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_sql_query(\"\"\" SELECT * FROM Reviews\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = final[final.Score == 'positive']\n",
    "positive = positive.sample(frac=0.035,random_state=1)\n",
    "\n",
    "negative = final[final.Score == 'negative']\n",
    "negative = negative.sample(frac=0.15,random_state=1)\n",
    "\n",
    "final = pd.concat([positive,negative],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "final[\"Time\"] = final[\"Time\"].map(lambda t: datetime.datetime.fromtimestamp(int(t)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "final = final.sort_values('Time',axis=0,kind=\"quicksort\", ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = final['Score']\n",
    "final = final.drop(\"Score\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final, l, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordList(sentence):\n",
    "    listword = []\n",
    "    for sent in sentence:\n",
    "        listword.append(sent.split())\n",
    "    return listword\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e89d46388582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_clean_text_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CleanedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wordList' is not defined"
     ]
    }
   ],
   "source": [
    "list_clean_text_train = wordList(X_train['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_clean_text_test = wordList(X_test['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering Words with minimum occurence of 5 times\n",
    "w2v_model = Word2Vec(list_clean_text, min_count = 5, size = 50, workers = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words occuring more than 5 times 4479\n",
      "sample words ['recent', 'purchas', 'corp', 'gopher', 'trap', 'within', 'minut', 'lay', 'catch', 'product', 'best', 'ever', 'use', 'easi', 'set', 'work', 'great', 'success', 'also', 'rememb', 'wire', 'attach', 'tie', 'steak', 'prevent', 'drag', 'hole', 'caught', 'hope', 'find', 'good', 'luck', 'michael', 'bring', 'distinguish', 'characterist', 'beetlejuic', 'mere', 'act', 'bizarr', 'often', 'stun', 'movi', 'come', 'focus', 'like', 'one', 'snack', 'popcorn', 'vacat']\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words occuring more than 5 times\", len(w2v_words))\n",
    "print(\"sample words\", w2v_words[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range = (1,2))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(X_train['CleanedText'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_idf_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3cc4adb968bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_idf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tfidf words/col-names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_idf_vect' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "def tfidfw2v(final_tf_idf,tfidf_feat,list_clean_text,w2v_model,w2v_words):\n",
    "    tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "    row=0;\n",
    "    for sent in list_clean_text: # for each review/sentence \n",
    "        sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "        weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "        for word in sent: # for each word in a review/sentence\n",
    "            if (word in w2v_words and (word in tfidf_feat)):\n",
    "                vec = w2v_model.wv[word]\n",
    "                # obtain the tf_idfidf of a word in a sentence/review\n",
    "                tf_idf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "                sent_vec += (vec * tf_idf)\n",
    "                weight_sum += tf_idf\n",
    "                \n",
    "        if weight_sum != 0:\n",
    "            sent_vec /= weight_sum\n",
    "        tfidf_sent_vectors.append(sent_vec)\n",
    "        row += 1\n",
    "    return tfidf_sent_vectors.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors_train = tfidfw2v(final_tf_idf,tfidf_feat,list_clean_text_train,w2v_model,w2v_words)\n",
    "print(len(sent_vectors_train))\n",
    "print(len(sent_vectors_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors_test = tfidfw2v(final_tf_idf,tfidf_feat,list_clean_text_test,w2v_model,w2v_words)\n",
    "print(len(sent_vectors_train))\n",
    "print(len(sent_vectors_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors_final_train = np.asarray(sent_vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors_final_test = np.asarray(sent_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sent_vectors_final_train.shape)\n",
    "print(sent_vectors_final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_data = s.fit_transform(sent_vectors_final_train)\n",
    "standardized_data_test = s.transform(sent_vectors_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standardized_data.shape)\n",
    "print(standardized_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneigh(x,y,algo):\n",
    "    myList = list(range(0,50))\n",
    "    neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "    cv_scores = []\n",
    "    for k in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k,algorithm=algo, n_jobs = -1) # Creating K-NN classifier with KD3 Algorithm\n",
    "        scores = cross_val_score(knn, x, y, cv=10, scoring='accuracy')\n",
    "        cv_scores.append(scores.mean())\n",
    "     \n",
    "    MSE = [1 - x for x in cv_scores]\n",
    "    optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "    plt.plot(neighbors, MSE,color='blue', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\n",
    "    plt.xlabel('Number of Neighbors K')\n",
    "    plt.ylabel('Misclassification Error')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"the misclassification error for each k value is : \", np.round(MSE,3))\n",
    "    return optimal_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneighpredict(k,x,y,z,algo):\n",
    "    knn_optimal = KNeighborsClassifier(n_neighbors=k, algorithm=algo, n_jobs = -1)\n",
    "    knn_optimal.fit(x, y)\n",
    "    pred = knn_optimal.predict(z)\n",
    "    acc = accuracy_score(y_test, pred) * 100\n",
    "    skplt.plot_confusion_matrix(y_test ,pred)\n",
    "    print(classification_report(y_test ,pred))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = kneigh(standardized_data,y_train,'kd_tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = kneighpredict(optimal_k,standardized_data,y_train,standardized_data_test ,'kd_tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = kneigh(standardized_data,y_train,'brute')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = kneighpredict(optimal_k,standardized_data,y_train,standardized_data_test ,'kd_tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
