{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('/mydata/database.sqlite')\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", con) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering data \n",
    "#1)Ignoring data which has score = 3\n",
    "#2) Changing score to positive if score > 3\n",
    "#3) Changing score to positive if score < 3\n",
    "\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition)\n",
    "filtered_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78445</td>\n",
       "      <td>B000HDL1RQ</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138317</td>\n",
       "      <td>B000HDOPYC</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138277</td>\n",
       "      <td>B000HDOPYM</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73791</td>\n",
       "      <td>B000HDOPZG</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155049</td>\n",
       "      <td>B000PAQ75C</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId         UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "0   78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "1  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "2  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "3   73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "4  155049  B000PAQ75C  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time  \\\n",
       "0                       2      5  1199577600   \n",
       "1                       2      5  1199577600   \n",
       "2                       2      5  1199577600   \n",
       "3                       2      5  1199577600   \n",
       "4                       2      5  1199577600   \n",
       "\n",
       "                             Summary  \\\n",
       "0  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "1  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "2  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "3  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "4  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "\n",
       "                                                Text  \n",
       "0  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "1  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "2  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "3  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "4  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#found deduplication\n",
    "#Example\n",
    "\n",
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND UserId=\"AR5J8UI46CURR\"\n",
    "ORDER BY ProductID\n",
    "\"\"\", con)\n",
    "\n",
    "display.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above the same user has multiple reviews of the with the same values for HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary and Text and on doing analysis it was found that \n",
    "\n",
    "ProductId=B000HDOPZG was Loacker Quadratini Vanilla Wafer Cookies, 8.82-Ounce Packages (Pack of 8)\n",
    "\n",
    "ProductId=B000HDL1RQ was Loacker Quadratini Lemon Wafer Cookies, 8.82-Ounce Packages (Pack of 8) and so on\n",
    "\n",
    "It was inferred after analysis that reviews with same parameters other than ProductId belonged to the same product just having different flavour or quantity. Hence in order to reduce redundancy it was decided to eliminate the rows having same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.25890143662969"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking to see how much % of data still remains\n",
    "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id   ProductId          UserId              ProfileName  \\\n",
       "0  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "1  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     3                       1      5  1224892800   \n",
       "1                     3                       2      4  1212883200   \n",
       "\n",
       "                                        Summary  \\\n",
       "0             Bought This for My Son at College   \n",
       "1  Pure cocoa taste with crunchy almonds inside   \n",
       "\n",
       "                                                Text  \n",
       "0  My son loves spaghetti so I didn't hesitate or...  \n",
       "1  It was almost a 'love at first bite' - the per...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND Id=44737 OR Id=64422\n",
    "ORDER BY ProductID\n",
    "\"\"\", con)\n",
    "\n",
    "display.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:- It can be seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'very', 'we', 'over', 'because', 'and', 'during', 'hers', 'which', \"that'll\", 'here', 'what', 'its', 'if', \"needn't\", 'again', 'theirs', 'of', 'or', 'ourselves', 'should', 'few', 'himself', 'it', 'once', \"weren't\", 'can', 'until', \"hadn't\", \"you'll\", \"hasn't\", 'an', 'each', 'out', 'after', 'own', 'itself', 'being', 'ours', 'whom', 'isn', 'aren', 'ma', 'a', 'all', 'that', 's', 'any', 'i', \"she's\", 'both', \"you'd\", 'with', 'wasn', 'below', 'doesn', 'by', 'myself', 'who', 'weren', 'having', 'didn', 'you', 'did', 'doing', \"aren't\", 'while', 'most', 'me', 'll', 'him', 'now', 'when', 'couldn', 'too', 'how', \"you're\", \"don't\", 'just', 'nor', 'above', 'are', 'needn', \"couldn't\", 'is', 'before', 'they', 'their', 'mightn', 'on', 'off', 'only', \"shan't\", 'herself', 'from', 'other', 'those', 'where', \"haven't\", 'this', 'm', 've', 'through', \"isn't\", 'won', 'am', 'don', 'yours', 'ain', 're', \"mustn't\", 'against', 'haven', \"you've\", 'she', 'up', 'be', 'mustn', 'her', 'as', 'does', \"shouldn't\", 'so', 'has', \"it's\", 'under', 'not', 'were', \"won't\", 'same', 'more', 't', 'do', 'hadn', 'some', 'them', 'further', 'down', \"didn't\", 'y', \"doesn't\", 'will', \"should've\", 'into', 'the', \"wouldn't\", 'for', 'd', 'no', 'wouldn', 'there', 'why', 'yourself', 'about', 'had', 'shan', 'these', 'between', 'at', 'themselves', 'your', 'was', 'to', 'in', 'then', \"mightn't\", 'have', 'his', 'our', 'yourselves', 'such', 'been', 'hasn', \"wasn't\", 'shouldn', 'o', 'he', 'but', 'than', 'my'}\n",
      "************************************\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "print(stop)\n",
    "print('************************************')\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t= this\n",
      "cleaned 1 this\n",
      "cleaned 2 this\n",
      "t= witty\n",
      "cleaned 1 witty\n",
      "cleaned 2 witty\n",
      "cleaned 3 witty\n",
      "t= little\n",
      "cleaned 1 little\n",
      "cleaned 2 little\n",
      "cleaned 3 little\n",
      "t= book\n",
      "cleaned 1 book\n",
      "cleaned 2 book\n",
      "cleaned 3 book\n",
      "t= makes\n",
      "cleaned 1 makes\n",
      "cleaned 2 makes\n",
      "cleaned 3 makes\n",
      "t= my\n",
      "cleaned 1 my\n",
      "t= son\n",
      "cleaned 1 son\n",
      "cleaned 2 son\n",
      "cleaned 3 son\n",
      "t= laugh\n",
      "cleaned 1 laugh\n",
      "cleaned 2 laugh\n",
      "cleaned 3 laugh\n",
      "t= at\n",
      "cleaned 1 at\n",
      "t= loud.\n",
      "cleaned 1 loud\n",
      "cleaned 2 loud\n",
      "cleaned 3 loud\n",
      "t= i\n",
      "cleaned 1 i\n",
      "t= recite\n",
      "cleaned 1 recite\n",
      "cleaned 2 recite\n",
      "cleaned 3 recite\n",
      "t= it\n",
      "cleaned 1 it\n",
      "t= in\n",
      "cleaned 1 in\n",
      "t= the\n",
      "cleaned 1 the\n",
      "cleaned 2 the\n",
      "t= car\n",
      "cleaned 1 car\n",
      "cleaned 2 car\n",
      "cleaned 3 car\n",
      "t= as\n",
      "cleaned 1 as\n",
      "t= we're\n",
      "cleaned 1 were\n",
      "cleaned 2 were\n",
      "t= driving\n",
      "cleaned 1 driving\n",
      "cleaned 2 driving\n",
      "cleaned 3 driving\n",
      "t= along\n",
      "cleaned 1 along\n",
      "cleaned 2 along\n",
      "cleaned 3 along\n",
      "t= and\n",
      "cleaned 1 and\n",
      "cleaned 2 and\n",
      "t= he\n",
      "cleaned 1 he\n",
      "t= always\n",
      "cleaned 1 always\n",
      "cleaned 2 always\n",
      "cleaned 3 always\n",
      "t= can\n",
      "cleaned 1 can\n",
      "cleaned 2 can\n",
      "t= sing\n",
      "cleaned 1 sing\n",
      "cleaned 2 sing\n",
      "cleaned 3 sing\n",
      "t= the\n",
      "cleaned 1 the\n",
      "cleaned 2 the\n",
      "t= refrain.\n",
      "cleaned 1 refrain\n",
      "cleaned 2 refrain\n",
      "cleaned 3 refrain\n",
      "t= he's\n",
      "cleaned 1 hes\n",
      "cleaned 2 hes\n",
      "cleaned 3 hes\n",
      "t= learned\n",
      "cleaned 1 learned\n",
      "cleaned 2 learned\n",
      "cleaned 3 learned\n",
      "t= about\n",
      "cleaned 1 about\n",
      "cleaned 2 about\n",
      "t= whales,\n",
      "cleaned 1 whales\n",
      "cleaned 2 whales\n",
      "cleaned 3 whales\n",
      "t= India,\n",
      "cleaned 1 India\n",
      "cleaned 2 India\n",
      "cleaned 3 India\n",
      "t= drooping\n",
      "cleaned 1 drooping\n",
      "cleaned 2 drooping\n",
      "cleaned 3 drooping\n",
      "t= roses:\n",
      "cleaned 1 roses:\n",
      "t= i\n",
      "cleaned 1 i\n",
      "t= love\n",
      "cleaned 1 love\n",
      "cleaned 2 love\n",
      "cleaned 3 love\n",
      "t= all\n",
      "cleaned 1 all\n",
      "cleaned 2 all\n",
      "t= the\n",
      "cleaned 1 the\n",
      "cleaned 2 the\n",
      "t= new\n",
      "cleaned 1 new\n",
      "cleaned 2 new\n",
      "cleaned 3 new\n",
      "t= words\n",
      "cleaned 1 words\n",
      "cleaned 2 words\n",
      "cleaned 3 words\n",
      "t= this\n",
      "cleaned 1 this\n",
      "cleaned 2 this\n",
      "t= book\n",
      "cleaned 1 book\n",
      "cleaned 2 book\n",
      "cleaned 3 book\n",
      "t= introduces\n",
      "cleaned 1 introduces\n",
      "cleaned 2 introduces\n",
      "cleaned 3 introduces\n",
      "t= and\n",
      "cleaned 1 and\n",
      "cleaned 2 and\n",
      "t= the\n",
      "cleaned 1 the\n",
      "cleaned 2 the\n",
      "t= silliness\n",
      "cleaned 1 silliness\n",
      "cleaned 2 silliness\n",
      "cleaned 3 silliness\n",
      "t= of\n",
      "cleaned 1 of\n",
      "t= it\n",
      "cleaned 1 it\n",
      "t= all.\n",
      "cleaned 1 all\n",
      "cleaned 2 all\n",
      "t= this\n",
      "cleaned 1 this\n",
      "cleaned 2 this\n",
      "t= is\n",
      "cleaned 1 is\n",
      "t= a\n",
      "cleaned 1 a\n",
      "t= classic\n",
      "cleaned 1 classic\n",
      "cleaned 2 classic\n",
      "cleaned 3 classic\n",
      "t= book\n",
      "cleaned 1 book\n",
      "cleaned 2 book\n",
      "cleaned 3 book\n",
      "t= i\n",
      "cleaned 1 i\n",
      "t= am\n",
      "cleaned 1 am\n",
      "t= willing\n",
      "cleaned 1 willing\n",
      "cleaned 2 willing\n",
      "cleaned 3 willing\n",
      "t= to\n",
      "cleaned 1 to\n",
      "t= bet\n",
      "cleaned 1 bet\n",
      "cleaned 2 bet\n",
      "cleaned 3 bet\n",
      "t= my\n",
      "cleaned 1 my\n",
      "t= son\n",
      "cleaned 1 son\n",
      "cleaned 2 son\n",
      "cleaned 3 son\n",
      "t= will\n",
      "cleaned 1 will\n",
      "cleaned 2 will\n",
      "t= STILL\n",
      "cleaned 1 STILL\n",
      "cleaned 2 STILL\n",
      "cleaned 3 STILL\n",
      "t= be\n",
      "cleaned 1 be\n",
      "t= able\n",
      "cleaned 1 able\n",
      "cleaned 2 able\n",
      "cleaned 3 able\n",
      "t= to\n",
      "cleaned 1 to\n",
      "t= recite\n",
      "cleaned 1 recite\n",
      "cleaned 2 recite\n",
      "cleaned 3 recite\n",
      "t= from\n",
      "cleaned 1 from\n",
      "cleaned 2 from\n",
      "t= memory\n",
      "cleaned 1 memory\n",
      "cleaned 2 memory\n",
      "cleaned 3 memory\n",
      "t= when\n",
      "cleaned 1 when\n",
      "cleaned 2 when\n",
      "t= he\n",
      "cleaned 1 he\n",
      "t= is\n",
      "cleaned 1 is\n",
      "t= in\n",
      "cleaned 1 in\n",
      "t= college\n",
      "cleaned 1 college\n",
      "cleaned 2 college\n",
      "cleaned 3 college\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "for sent in final['Text'].values:\n",
    "    sent = cleanhtml(sent)\n",
    "    filtered_sentence = []\n",
    "    for t in sent.split():\n",
    "        if i == 0:\n",
    "            print (\"t= \"+t)\n",
    "        for cleaned in cleanpunc(t).split():\n",
    "            if i == 0:\n",
    "                print (\"cleaned 1 \"+cleaned)\n",
    "            if ((cleaned.isalpha()) & (len(cleaned) > 2)):\n",
    "                if i==0:\n",
    "                    print (\"cleaned 2 \"+cleaned)\n",
    "                if (cleaned.lower() not in stop):\n",
    "                    if i==0:\n",
    "                        print (\"cleaned 3 \"+cleaned)\n",
    "                    s=(sno.stem(cleaned.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if(final['Score'].values)[i] == 'positive':\n",
    "                        positive_words.append(s)\n",
    "                    if(final['Score'].values)[i] == 'negative':\n",
    "                        negative_words.append(s)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    #print(filtered_sentence)    \n",
    "    str1 = b\" \".join(filtered_sentence)\n",
    "    final_string.append(str1)\n",
    "    i+=1\n",
    "    \n",
    "                    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \n",
    "final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('final.sqlite')\n",
    "c=conn.cursor()\n",
    "conn.text_factory = str\n",
    "final.to_sql('Reviews', conn,  schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
